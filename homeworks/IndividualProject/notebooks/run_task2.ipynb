{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/task2.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "draft_ids = list(df['Original_id'])\n",
    "\n",
    "# input data\n",
    "countries = list(df['Country'])\n",
    "drafts = []\n",
    "votes = list(df['Voting'])\n",
    "\n",
    "path = '../data/task2'\n",
    "for i in draft_ids:\n",
    "    folder_path = os.path.join(path, str(i))\n",
    "    files = os.listdir(folder_path)\n",
    "    json_file = [file for file in files if file.endswith('EN.json')][0]\n",
    "    with open(os.path.join(folder_path, json_file)) as f:\n",
    "        draft = json.load(f)\n",
    "    drafts.append(draft['Content'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-Ooc91cMDpYKCCnuIfmfe8nzJhZVo5IHJlfLSkJs9t3hAmSUG\",\n",
    "    base_url=\"https://hiapi.online/v1\"\n",
    ")\n",
    "\n",
    "your_model_name = \"gemini-3-flash-preview\"\n",
    "\n",
    "pred = []\n",
    "detailed_logs = []\n",
    "\n",
    "for i, (draft, country) in tqdm(enumerate(zip(drafts, countries))):\n",
    "\n",
    "\n",
    "    system_prompt = f\"You are a strategic diplomat for {country}. Analyze the UNSC draft resolution based on national interests before casting a formal vote.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Draft Resolution: {draft}\n",
    "\n",
    "    Task:\n",
    "    1. Analyze the core impact on {country}.\n",
    "    2. Provide your final vote in the format: \"RESULT: [Y/N/A]\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=your_model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.0,\n",
    "            top_p=0.1,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        raw_output = response.choices[0].message.content.strip()\n",
    "        detailed_logs.append(raw_output)\n",
    "\n",
    "        match = re.search(r\"RESULT:\\s*([YNA])\", raw_output, re.IGNORECASE)\n",
    "        if match:\n",
    "            result = match.group(1).upper()\n",
    "        else:\n",
    "            clean_output = raw_output.upper()\n",
    "            if 'RESULT: Y' in clean_output: result = 'Y'\n",
    "            elif 'RESULT: N' in clean_output: result = 'N'\n",
    "            elif 'RESULT: A' in clean_output: result = 'A'\n",
    "            else:\n",
    "                result = \"INVALID\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error at index {i}: {e}\")\n",
    "        result = \"ERROR\"\n",
    "\n",
    "    pred.append(result)\n",
    "\n",
    "valid_count = sum(1 for p in pred if p in ['Y', 'N', 'A'])\n",
    "print(f\"\\n执行完毕。有效预测率: {valid_count/len(pred):.2%}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# calculate metrics\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(pred, labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_classes = list(set(labels) | set(pred))  \n",
    "    label_encoder.fit(all_classes)\n",
    "\n",
    "    labels = label_encoder.transform(labels) \n",
    "    pred = label_encoder.transform(pred)  \n",
    "\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    \n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    true_labels_bin = label_binarize(labels, classes=list(range(num_classes)))\n",
    "    pred_bin = label_binarize(pred, classes=list(range(num_classes)))  \n",
    "\n",
    "    auc = roc_auc_score(true_labels_bin, pred_bin, multi_class='ovr', average='macro')\n",
    "    pr_auc = average_precision_score(true_labels_bin, pred_bin, average='macro')\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(labels, pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, pred, average='macro')\n",
    "\n",
    "    mcc = matthews_corrcoef(labels, pred)\n",
    "    g_mean = geometric_mean_score(labels, pred, average='macro')\n",
    "\n",
    "    print(f'Accuracy: {acc}')\n",
    "    print(f'AUC: {auc}')\n",
    "    print(f'Balanced Accuracy: {balanced_acc}')\n",
    "    print(f'Precision: {prec}')\n",
    "    print(f'Recall: {rec}')\n",
    "    print(f'F1: {f1}')\n",
    "    print(f'PR AUC: {pr_auc}')\n",
    "    print(f'MCC: {mcc}')\n",
    "    print(f'G-Mean: {g_mean}')\n",
    "\n",
    "    print('Accuracy AUC Balanced_Acc Precision Recall F1 PR_AUC MCC G-Mean')\n",
    "    print(f'{acc:.4f} {auc:.4f} {balanced_acc:.4f} {prec:.4f} {rec:.4f} {f1:.4f} {pr_auc:.4f} {mcc:.4f} {g_mean:.4f}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "calculate_metrics(pred, votes)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
